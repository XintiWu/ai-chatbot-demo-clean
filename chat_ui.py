import streamlit as st
import os

from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain

# å®‰å…¨åœ°è®€å– OpenAI API é‡‘é‘°ï¼ˆç”± Streamlit secrets æä¾›ï¼‰
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# åˆå§‹åŒ–å‘é‡è³‡æ–™åº«ï¼Œä½¿ç”¨å¿«å–é¿å…é‡è¤‡åŠ è¼‰
@st.cache_resource
def setup_vectorstore():
    loader = TextLoader("faq.txt", encoding="utf-8")
    docs = loader.load()
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    split_docs = splitter.split_documents(docs)
    embedding = OpenAIEmbeddings()
    return FAISS.from_documents(split_docs, embedding)

# åˆå§‹åŒ– LLM èˆ‡ QA Chain
vectorstore = setup_vectorstore()
llm = OpenAI(temperature=0)
chain = load_qa_chain(llm, chain_type="stuff")

# Streamlit UI
st.set_page_config(page_title="AI æ ¡å‹™å•ç­”æ©Ÿå™¨äºº ğŸ¤–")
st.title("ğŸ¤– AI æ ¡å‹™å®¢æœ ChatBot")
query = st.text_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œ")

if query:
    docs = vectorstore.similarity_search(query)
    answer = chain.run(input_documents=docs, question=query)
    st.write("### å›ç­”ï¼š")
    st.success(answer)
